{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Título  \\\n",
      "0  STEAM, PROJETOS E O PENSAMENTO COMPUTACIONAL N...   \n",
      "1  The SNS-based E-mentoring and Development of C...   \n",
      "2  Effects of a teacher development program on te...   \n",
      "3  Classroom Play and Activities to Support Compu...   \n",
      "4  How a Rubric Score Application Empowers Teache...   \n",
      "\n",
      "                                             Autores  \\\n",
      "0  de Almeida Rosa, Thais; de Lima Terçariol, Adr...   \n",
      "1  Yeonju Jang; Seongyune Choi; Seonghun Kim; Hye...   \n",
      "2                        Kong, Siu‐Cheung; Lai, Ming   \n",
      "3        Lee, Joohi; Joswick, Candace; Pole, Kathryn   \n",
      "4  Dimos, Ioannis; Velaora, Chrysoula; Louvaris, ...   \n",
      "\n",
      "                                     Revista         ISSN Fecha Publicacion  \\\n",
      "0                 Eccos - Revista Científica  =\"15171949\"    =\"abr-jun2023\"   \n",
      "1           Educational Technology & Society  =\"11763647\"        =\"Apr2023\"   \n",
      "2  British Journal of Educational Technology  =\"00071013\"        =\"Mar2023\"   \n",
      "3          Early Childhood Education Journal  =\"10823301\"        =\"Mar2023\"   \n",
      "4                    Information (2078-2489)  =\"20782489\"        =\"Feb2023\"   \n",
      "\n",
      "                              DOI  \\\n",
      "0         10.5585/eccos.n65.24626   \n",
      "1  10.30191/ETS.202304_26(2).0011   \n",
      "2              10.1111/bjet.13256   \n",
      "3      10.1007/s10643-022-01319-0   \n",
      "4            10.3390/info14020118   \n",
      "\n",
      "                                      Palabras Clave Volumen Asunto  \\\n",
      "0  basic education; computational thinking; eleme...     NaN     65   \n",
      "1  Computational thinking; Computational thinking...    26.0      2   \n",
      "2  collaborative engagement; computational thinki...    54.0      2   \n",
      "3  Algorithm; Computational thinking (CT); CT pra...    51.0      3   \n",
      "4  application; computational thinking; descripti...    14.0      2   \n",
      "\n",
      "  Primera Pagina  Paginas                                          Publisher  \\\n",
      "0              1     21.0                         Eccos - Revista Cientifica   \n",
      "1            147     18.0  International Forum of Educational Technology ...   \n",
      "2            489     24.0                                    Wiley-Blackwell   \n",
      "3            457     12.0                                    Springer Nature   \n",
      "4            118     20.0                                               MDPI   \n",
      "\n",
      "      Tipo                                           Abstract  \\\n",
      "0  Article  This article is an excerpt from a dissertation...   \n",
      "1  Article  Given the importance of digital technology in ...   \n",
      "2  Article  An important educational goal for the next gen...   \n",
      "3  Article  This is a conceptual paper based on existing l...   \n",
      "4  Article  Computational Thinking (CT) has emerged as an ...   \n",
      "\n",
      "                                                Link  \n",
      "0  https://crai.referencistas.com/login?url=https...  \n",
      "1  https://crai.referencistas.com/login?url=https...  \n",
      "2  https://crai.referencistas.com/login?url=https...  \n",
      "3  https://crai.referencistas.com/login?url=https...  \n",
      "4  https://crai.referencistas.com/login?url=https...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "base_unificada = r'C:\\Users\\nicof\\Documents\\Seguimiento1_Metodos_de_Ordenamiento\\bases_unificadas_ok.csv'\n",
    "\n",
    "df = pd.read_csv(base_unificada)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado por ISSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar la columna ISSN (remover =\" \" y cualquier caracter no numérico)\n",
    "df['ISSN'] = df['ISSN'].str.extract(r'(\\d{4}-?\\d{4})')\n",
    "\n",
    "# Filtrar los valores no nulos de ISSN\n",
    "issn_list = df['ISSN'].dropna().tolist()\n",
    "\n",
    "# Función de Insertion Sort (para ordenar cada cubo)\n",
    "def insertion_sort(arr):\n",
    "     # Iteramos desde el segundo elemento hasta el final del array\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]  # Guardamos el valor actual en 'key' este es el elemento a insertar\n",
    "        j = i - 1     # 'j' se inicializa en el índice del elemento anterior a 'key'\n",
    "        # Comparamos 'key' con los elementos en la parte ordenada del array\n",
    "        # que se encuentra a la izquierda de 'key'\n",
    "        while j >= 0 and key < arr[j]:\n",
    "            # Si 'key' es menor que el elemento en la posición 'j',\n",
    "            # movemos el elemento arr[j] una posición hacia la derecha\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1  # Decrementamos 'j' para continuar comparando con el siguiente elemento\n",
    "            # Una vez que encontramos la posición correcta para 'key',\n",
    "        # lo insertamos en su lugar\n",
    "        arr[j + 1] = key\n",
    "\n",
    "# Implementación de Bucket Sort\n",
    "def bucket_sort(arr):\n",
    "    max_val = max(arr)  # valor máximo para normalizar\n",
    "    min_val = min(arr)  # valor mínimo para normalizar\n",
    "    n = len(arr)\n",
    "    \n",
    "    # Normalizar los elementos al rango [0, 1]\n",
    "    normalized = [(num - min_val) / (max_val - min_val) for num in arr]\n",
    "\n",
    "    # Crear una lista de \"cubos\" vacíos\n",
    "    buckets = [[] for _ in range(n)]\n",
    "\n",
    "    # Distribuir los elementos en los cubos\n",
    "    for num in normalized:\n",
    "        index = int(num * (n - 1))\n",
    "        buckets[index].append(num)\n",
    "\n",
    "    # Ordenar cada cubo individualmente\n",
    "    for bucket in buckets:\n",
    "        insertion_sort(bucket)\n",
    "\n",
    "    # Concatenar los cubos ordenados\n",
    "    sorted_arr = []\n",
    "    for bucket in buckets:\n",
    "        sorted_arr.extend(bucket)\n",
    "\n",
    "    # Desnormalizar los elementos al rango original\n",
    "    sorted_arr = [min_val + num * (max_val - min_val) for num in sorted_arr]\n",
    "    return sorted_arr\n",
    "\n",
    "# Medir tiempo de ejecución\n",
    "def measure_execution(arr, num_executions=4):\n",
    "    times = []\n",
    "    sizes = []\n",
    "    \n",
    "    for _ in range(num_executions):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ejecutar el algoritmo Bucket Sort\n",
    "        sorted_issn = bucket_sort(arr)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        # Guardar el tiempo y el tamaño de los datos procesados\n",
    "        times.append(execution_time)\n",
    "        sizes.append(len(arr))\n",
    "        \n",
    "    return times, sizes\n",
    "\n",
    "# Filtrar correctamente solo los ISSN que tengan 8 dígitos (con o sin guion)\n",
    "issn_as_ints = [int(issn.replace('-', '')) for issn in issn_list if len(issn.replace('-', '')) == 8]\n",
    "\n",
    "# Medir tiempos de ejecución\n",
    "execution_times, data_sizes = measure_execution(issn_as_ints)\n",
    "\n",
    "# Imprimir los tiempos de ejecución y tamaños de los datos\n",
    "print(\"Estos son los tiempos de ejecución (en segundos):\")\n",
    "for idx, time_exec in enumerate(execution_times):\n",
    "    print(f\"{idx + 1}ª ejecución: {time_exec:.5f} s\")\n",
    "\n",
    "print(\"\\nEste es el tamaño de los elementos procesados:\")\n",
    "print(f\"Tamaño: {data_sizes[0]} elementos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado por autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de Bucket Sort para cadenas (orden alfabético)\n",
    "def bucket_sort_strings(arr):\n",
    "    # Crear una lista de 26 cubos (uno para cada letra del alfabeto)\n",
    "    buckets = [[] for _ in range(26)]\n",
    "\n",
    "    # Función auxiliar para obtener el índice del bucket en función del primer carácter\n",
    "    def get_bucket_index(author):\n",
    "        if author and author[0].isalpha():  # Verificar si el primer carácter es una letra\n",
    "            first_char = author[0].upper()  # Asegurar que sea mayúscula\n",
    "            index = ord(first_char) - ord('A')  # Convertir la letra en un índice (0-25)\n",
    "            if 0 <= index < 26:  # Verificar que el índice esté dentro del rango\n",
    "                return index\n",
    "        return None  # Retornar None si no es una letra o si el índice no es válido\n",
    "\n",
    "    # Distribuir los autores en los cubos\n",
    "    for author in arr:\n",
    "        index = get_bucket_index(author)\n",
    "        if index is not None:  # Solo añadir si el índice es válido\n",
    "            buckets[index].append(author)\n",
    "\n",
    "    # Concatenar los cubos para formar el arreglo ordenado final (ya ordenado por los buckets)\n",
    "    sorted_arr = []\n",
    "    for bucket in buckets:\n",
    "        sorted_arr.extend(bucket)\n",
    "\n",
    "    return sorted_arr\n",
    "\n",
    "# Medir tiempo de ejecución\n",
    "def measure_execution_strings(arr, num_executions=4):\n",
    "    times = []\n",
    "    sizes = []\n",
    "    \n",
    "    for _ in range(num_executions):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ejecutar el algoritmo Bucket Sort\n",
    "        sorted_authors = bucket_sort_strings(arr)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        # Guardar el tiempo y el tamaño de los datos procesados\n",
    "        times.append(execution_time)\n",
    "        sizes.append(len(arr))\n",
    "        \n",
    "    return times, sizes\n",
    "\n",
    "# Buscar posibles columnas de autores en el archivo, ignorando espacios y mayúsculas\n",
    "possible_author_columns = ['autor', 'author', 'autores', 'authors']\n",
    "\n",
    "# Normalizar nombres de columnas del DataFrame (eliminar espacios y convertir a minúsculas)\n",
    "normalized_columns = {col.lower().strip(): col for col in df.columns}\n",
    "\n",
    "# Revisar si alguna de estas columnas existe en el archivo (después de normalizar)\n",
    "author_column = next((normalized_columns[col] for col in possible_author_columns if col in normalized_columns), None)\n",
    "\n",
    "# Si se encuentra una columna de autores, proceder con el ordenamiento\n",
    "if author_column:\n",
    "    # Obtener la lista de autores\n",
    "    author_list = df[author_column].dropna().tolist()\n",
    "\n",
    "    # Medir tiempos de ejecución\n",
    "    execution_times_authors, data_sizes_authors = measure_execution_strings(author_list)\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(f\"Se usó la columna '{author_column}' para ordenar.\")\n",
    "    print(\"Estos son los tiempos de ejecución (en segundos):\")\n",
    "    for idx, time_exec in enumerate(execution_times_authors):\n",
    "        print(f\"{idx + 1}ª ejecución: {time_exec:.5f} s\")\n",
    "\n",
    "    print(\"\\nEste es el tamaño de los elementos procesados:\")\n",
    "    print(f\"Tamaño: {data_sizes_authors[0]} elementos\")\n",
    "else:\n",
    "    print(\"No se encontró una columna relacionada con autores en el archivo CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar por fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se usó la columna 'Fecha Publicacion' para ordenar las fechas.\n",
      "Estos son los tiempos de ejecución (en segundos):\n",
      "1ª ejecución: 1.25856 s\n",
      "2ª ejecución: 1.22201 s\n",
      "3ª ejecución: 1.22347 s\n",
      "4ª ejecución: 1.18886 s\n",
      "\n",
      "Este es el tamaño de los elementos procesados:\n",
      "Tamaño: 7713 elementos\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Función para normalizar las fechas en diferentes formatos, incluso si falta el día, el mes o el año\n",
    "def normalize_date(date_str):\n",
    "    date_formats = [\n",
    "        \"%Y-%m-%d\",  # Formato estándar (ISO)\n",
    "        \"%d-%m-%Y\",  # Formato día-mes-año\n",
    "        \"%m/%d/%Y\",  # Formato mes/día/año\n",
    "        \"%d/%m/%Y\",  # Formato día/mes/año\n",
    "        \"%B %d, %Y\",  # Formato completo (ej. January 01, 2023)\n",
    "        \"%d %B %Y\",  # Formato día-mes-año (ej. 01 January 2023)\n",
    "        \"%Y\",  # Solo el año\n",
    "        \"%B %Y\",  # Mes y año (ej. January 2023)\n",
    "        \"%m-%Y\",  # Mes y año en formato numérico (ej. 01-2023)\n",
    "        \"%Y/%m\",  # Año/Mes (ej. 2023/01)\n",
    "    ]\n",
    "    \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str.strip(), fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None  # Retornar None si no se pudo convertir\n",
    "\n",
    "# Implementación de Bucket Sort para fechas normalizadas\n",
    "def bucket_sort_dates(arr):\n",
    "    # Normalizar las fechas primero\n",
    "    arr_normalized = [normalize_date(date) for date in arr if normalize_date(date) is not None]\n",
    "    \n",
    "    if not arr_normalized:\n",
    "        return []\n",
    "\n",
    "    # Crear una lista de 12 cubos (uno para cada mes)\n",
    "    min_date, max_date = min(arr_normalized), max(arr_normalized)\n",
    "    range_of_dates = (max_date - min_date).days\n",
    "    \n",
    "    # Inicializar cubos para cada grupo de fechas\n",
    "    buckets = [[] for _ in range(12)]\n",
    "\n",
    "    # Distribuir las fechas normalizadas en los cubos\n",
    "    for date in arr_normalized:\n",
    "        # Normalizar el índice del bucket según el mes de la fecha\n",
    "        index = date.month - 1  # Meses del 1 al 12, convertidos a 0 a 11\n",
    "        buckets[index].append(date)\n",
    "\n",
    "    # Ordenar los cubos y concatenar los resultados\n",
    "    sorted_arr = []\n",
    "    for bucket in buckets:\n",
    "        sorted_arr.extend(sorted(bucket))\n",
    "\n",
    "    return sorted_arr\n",
    "\n",
    "# Medir tiempo de ejecución para fechas\n",
    "def measure_execution_dates(arr, num_executions=4):\n",
    "    times = []\n",
    "    sizes = []\n",
    "    \n",
    "    for _ in range(num_executions):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ejecutar el algoritmo Bucket Sort\n",
    "        sorted_dates = bucket_sort_dates(arr)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        # Guardar el tiempo y el tamaño de los datos procesados\n",
    "        times.append(execution_time)\n",
    "        sizes.append(len(arr))\n",
    "        \n",
    "    return times, sizes\n",
    "\n",
    "# Buscar posibles columnas de fecha en el archivo, ignorando espacios y mayúsculas\n",
    "possible_date_columns = [\n",
    "    'fecha', 'publication_date', 'date', 'fecha_publicacion', \n",
    "    'fecha de publicacion', 'fecha_de_publicacion', 'published', \n",
    "    'date of publication', 'pub_date'\n",
    "]\n",
    "\n",
    "# Normalizar nombres de columnas del DataFrame (eliminar espacios y convertir a minúsculas)\n",
    "normalized_columns = {col.lower().replace(' ', '_').strip(): col for col in df.columns}\n",
    "\n",
    "# Revisar si alguna de estas columnas existe en el archivo (después de normalizar)\n",
    "date_column = next((normalized_columns[col] for col in possible_date_columns if col in normalized_columns), None)\n",
    "\n",
    "# Si se encuentra una columna de fechas, proceder con el ordenamiento\n",
    "if date_column:\n",
    "    # Obtener la lista de fechas\n",
    "    date_list = df[date_column].dropna().tolist()\n",
    "\n",
    "    # Medir tiempos de ejecución\n",
    "    execution_times_dates, data_sizes_dates = measure_execution_dates(date_list)\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(f\"Se usó la columna '{date_column}' para ordenar las fechas.\")\n",
    "    print(\"Estos son los tiempos de ejecución (en segundos):\")\n",
    "    for idx, time_exec in enumerate(execution_times_dates):\n",
    "        print(f\"{idx + 1}ª ejecución: {time_exec:.5f} s\")\n",
    "\n",
    "    print(\"\\nEste es el tamaño de los elementos procesados:\")\n",
    "    print(f\"Tamaño: {data_sizes_dates[0]} elementos\")\n",
    "else:\n",
    "    print(\"No se encontró una columna relacionada con fechas en el archivo CSV.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
